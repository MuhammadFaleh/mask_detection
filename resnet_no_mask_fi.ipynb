{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac14555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.checkpoint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision import models\n",
    "from torchvision.io import read_image\n",
    "from torchvision.io import write_png\n",
    "from torchvision.io import ImageReadMode\n",
    "import torchvision.transforms.functional as transform_fun\n",
    "from torchvision.datasets import ImageFolder\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "from torchvision.utils import save_image\n",
    "import glob\n",
    "import data_loader as DL\n",
    "import os, shutil\n",
    "import cv2\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "954a76d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else  'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1873fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for if gpu mem is full\n",
    "import torch\n",
    "\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "\n",
    "free_gpu_cache()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82338ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_path_test = 'raw/test/Masked/*.png'\n",
    "Nomask_path_test ='raw/test/Nomask/*.png'\n",
    "\n",
    "\n",
    "masked_path_train = 'raw/train/Masked/*'\n",
    "Nomask_path_train ='raw/train/Nomask/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67e29f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_train_masked = 'Train_std/masked' \n",
    "stand_train_Nomask = 'Train_std/Nomask' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df7cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Train_std'\n",
    "test_path = 'test2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af02d6c",
   "metadata": {},
   "source": [
    "## class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ac57d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the paths into a list\n",
    "list_mask_paths = glob.glob(masked_path_train)\n",
    "list_Nomask_paths = glob.glob(Nomask_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9465ccff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "list_names = ['Mask','No Mask']\n",
    "data = [len(list_mask_paths) ,len(list_Nomask_paths)]\n",
    "\n",
    "ax.bar(list_names,data,color=['blue', 'green'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "206c51ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3539, 3589)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_mask_paths) , len(list_Nomask_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb6a23",
   "metadata": {},
   "source": [
    "we can see that the dataset balanced we don't need to balance it , but we need to resize it and to augment it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b37a4",
   "metadata": {},
   "source": [
    "## data augment / resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f673b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files(path,Npath):\n",
    "    if not os.path.exists(Npath):\n",
    "        os.makedirs(Npath)\n",
    "    \n",
    "    for file in path:\n",
    "        try:\n",
    "            os.rename(file, Npath+'/'+file[22:])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "905f453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(path,Npath,size):\n",
    "    aug = torch.nn.Sequential(\n",
    "        transforms.Resize((size,size)),\n",
    "        transforms.ColorJitter(brightness=0.5),\n",
    "        transforms.RandomHorizontalFlip(p=0.25),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        transforms.RandomInvert(p=0.1),\n",
    "        transforms.RandomEqualize(p=0.1),\n",
    "        transforms.RandomPosterize(p=0.1,bits=8)\n",
    "    )\n",
    "    i = 1\n",
    "    transform = transforms.Compose([transforms.ToPILImage()])\n",
    "    transform2 = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    for file in path:\n",
    "        img = read_image(path=file, mode=ImageReadMode.RGB)\n",
    "        img = transform(img)\n",
    "        X = aug(img)\n",
    "        save_image(transform2(X).to(torch.float),fp=Npath+'/'+'__'+str(i)+'__.png')\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4e099b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize(glob.glob(masked_path_train),stand_train_masked,224)\n",
    "resize(glob.glob(Nomask_path_train),stand_train_Nomask,224)\n",
    "# resize(glob.glob('ready/ready/*.png'),stand_train_Nomask,224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa487f2",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a3de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "])\n",
    "\n",
    "train_data = ImageFolder(root=train_path, transform= transform)\n",
    "\n",
    "test_data = ImageFolder(root=test_path, transform= transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b21eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_load2 = DL.data_loader(train_data, 100,True)\n",
    "test_data_load2 = DL.data_loader(test_data,100,False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0d1455",
   "metadata": {},
   "source": [
    "## model loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d0bbe",
   "metadata": {},
   "source": [
    "this is a pretrained resnet50 we would only need to tune it but first let's change the output of the classifer layer to fit our case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "918c8c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.manual_seed(42)\n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    "print(model)\n",
    "for para in model.parameters():\n",
    "    para.requires_grad = False\n",
    "# frezing every layer apart from the first and last\n",
    "num_feats = model.fc.in_features\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.fc = nn.Linear(in_features=num_feats, out_features=2, bias=True) # we only have three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d04d1057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=2, bias=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the last layer\n",
    "model.to(device)\n",
    "model.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b55a941",
   "metadata": {},
   "source": [
    "## Loss function and optim function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f11267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# nn.BCEWithLogitsLoss()\n",
    "step = torch.optim.lr_scheduler.StepLR(optim,step_size=10,gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d4d17e",
   "metadata": {},
   "source": [
    "## train test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a379c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_ac(test_labels,model):\n",
    "    y_proba,y_pred,y_true = test_model(test_labels,model)\n",
    "    cnf_matrix=confusion_matrix(y_true,y_pred)\n",
    "    recall = cnf_matrix[1,1]/(cnf_matrix[1,1]+cnf_matrix[1,0])\n",
    "    ac = (cnf_matrix[1,1,] + cnf_matrix[0,0]) / (cnf_matrix[1,1,] + cnf_matrix[0,0] + cnf_matrix[0,1] + cnf_matrix[1,0])\n",
    "    pc = cnf_matrix[1,1,]/(cnf_matrix[1,1,]+cnf_matrix[0,1])\n",
    "    false_pos_rate = cnf_matrix[0,1] / (cnf_matrix[0,1] + cnf_matrix[0,0])\n",
    "    f1_score = (2*recall * pc) /( recall + pc)\n",
    "    \n",
    "\n",
    "    print(classification_report(y_true, y_pred, digits=5))\n",
    "    return recall,pc,ac,f1_score,false_pos_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21483752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_test_on_model(epochs,train_data_load,test_data_load,model):\n",
    "    train_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch}\\n-------\")\n",
    "        temp =0\n",
    "        \n",
    "        for batch, (X, y) in enumerate(train_data_load):\n",
    "                model.train(True)\n",
    "                X1,y1 = X.to(device),y.to(device)\n",
    "                y_pred = model(X1).squeeze()\n",
    "                loss = loss_fn(y_pred, y1)\n",
    "                temp += loss\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "        temp = 10   \n",
    "        temp /= len(train_data_load)\n",
    "        recall,pc,ac,f1_score,false_pos_rate = test_with_ac(test_data_load,model)\n",
    "        print(f\"\\nTrain loss: {temp:.5f} | Test f1: {f1_score:.4f}, Test acc: {ac:.4f}, Test PC {pc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fc3f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_data_load,model):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    y_proba = []\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X,y) in enumerate(test_data_load):\n",
    "                X1,y1 = X.to(device),y.to(device)\n",
    "#                 torch.softmax(y_pred_prob,dim=1).argmax(dim=1)\n",
    "                y_pred_prob = model(X1).squeeze()\n",
    "                temp = torch.softmax(y_pred_prob,dim=1).argmax(dim=1)\n",
    "                y_pred.extend(temp.to('cpu'))\n",
    "                y_true.extend(y1.to('cpu'))\n",
    "                y_proba.extend(y_pred_prob)\n",
    "    return y_proba,y_pred,y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad596a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_val(labels_test,pred, pred_proba):\n",
    "    cnf_matrix=confusion_matrix(labels_test,pred)\n",
    "#     print(\"AUC\",roc_auc_score(labels_test, pred_proba))\n",
    "    print(\"the recall for this model is :\",cnf_matrix[1,1]/(cnf_matrix[1,1]+cnf_matrix[1,0]))\n",
    "    fig= plt.figure(figsize=(6,3))# to plot the graph\n",
    "    print(cnf_matrix)\n",
    "    print(\"TP\",cnf_matrix[1,1,]) # no of fraud transaction which are predicted fraud\n",
    "    print(\"TN\",cnf_matrix[0,0]) # no. of normal transaction which are predited normal\n",
    "    print(\"FP\",cnf_matrix[0,1]) # no of normal transaction which are predicted fraud\n",
    "    print(\"FN\",cnf_matrix[1,0]) # no of fraud Transaction which are predicted normal\n",
    "    sns.heatmap(cnf_matrix,cmap=\"coolwarm_r\",annot=True,linewidths=0.5)\n",
    "    plt.title(\"Confusion_matrix\")\n",
    "    plt.xlabel(\"Predicted_class\")\n",
    "    plt.ylabel(\"Real class\")\n",
    "    plt.show()\n",
    "    print(\"\\n----------Classification Report------------------------------------\")\n",
    "    print(classification_report(labels_test,pred, digits=5))\n",
    "    print(classification_report_imbalanced(labels_test, pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ab48791",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.79686   0.84774   0.82151      1018\n",
      "           1    0.82797   0.77226   0.79914       966\n",
      "\n",
      "    accuracy                        0.81099      1984\n",
      "   macro avg    0.81241   0.81000   0.81033      1984\n",
      "weighted avg    0.81201   0.81099   0.81062      1984\n",
      "\n",
      "\n",
      "Train loss: 0.13889 | Test f1: 0.7991, Test acc: 0.8110, Test PC 0.8280\n",
      "\n",
      "Epoch: 1\n",
      "-------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.70575   0.92829   0.80187      1018\n",
      "           1    0.88682   0.59213   0.71012       966\n",
      "\n",
      "    accuracy                        0.76462      1984\n",
      "   macro avg    0.79629   0.76021   0.75599      1984\n",
      "weighted avg    0.79391   0.76462   0.75719      1984\n",
      "\n",
      "\n",
      "Train loss: 0.13889 | Test f1: 0.7101, Test acc: 0.7646, Test PC 0.8868\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93144   0.54715   0.68936      1018\n",
      "           1    0.66739   0.95756   0.78656       966\n",
      "\n",
      "    accuracy                        0.74698      1984\n",
      "   macro avg    0.79941   0.75235   0.73796      1984\n",
      "weighted avg    0.80287   0.74698   0.73669      1984\n",
      "\n",
      "\n",
      "Train loss: 0.13889 | Test f1: 0.7866, Test acc: 0.7470, Test PC 0.6674\n",
      "\n",
      "Epoch: 3\n",
      "-------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85000   0.83497   0.84242      1018\n",
      "           1    0.82927   0.84472   0.83692       966\n",
      "\n",
      "    accuracy                        0.83972      1984\n",
      "   macro avg    0.83963   0.83985   0.83967      1984\n",
      "weighted avg    0.83991   0.83972   0.83974      1984\n",
      "\n",
      "\n",
      "Train loss: 0.13889 | Test f1: 0.8369, Test acc: 0.8397, Test PC 0.8293\n",
      "\n",
      "Epoch: 4\n",
      "-------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.73306   0.88212   0.80071      1018\n",
      "           1    0.84190   0.66149   0.74087       966\n",
      "\n",
      "    accuracy                        0.77470      1984\n",
      "   macro avg    0.78748   0.77181   0.77079      1984\n",
      "weighted avg    0.78605   0.77470   0.77158      1984\n",
      "\n",
      "\n",
      "Train loss: 0.13889 | Test f1: 0.7409, Test acc: 0.7747, Test PC 0.8419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train_on_model(100,train_data_load) #10 + 5 +3 +3 +3+3 +3 +5 // 19_5 + 3 + 3\n",
    "# Train_on_model(1,val_data_load) 10 epoches\n",
    "Train_test_on_model(5,train_data_load2,test_data_load2,model) # 6 + 3 + 3 + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "734dbffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for para in model.parameters(): # unfrezing the rest and training for 4 epoch\n",
    "    para.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a98d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f1dd0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96526   0.90079   0.93191      1018\n",
      "           1    0.90232   0.96584   0.93300       966\n",
      "\n",
      "    accuracy                        0.93246      1984\n",
      "   macro avg    0.93379   0.93331   0.93246      1984\n",
      "weighted avg    0.93462   0.93246   0.93244      1984\n",
      "\n",
      "\n",
      "Train loss: 0.13889 | Test f1: 0.9330, Test acc: 0.9325, Test PC 0.9023\n",
      "\n",
      "Epoch: 1\n",
      "-------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96812   0.89489   0.93007      1018\n",
      "           1    0.89741   0.96894   0.93181       966\n",
      "\n",
      "    accuracy                        0.93095      1984\n",
      "   macro avg    0.93277   0.93192   0.93094      1984\n",
      "weighted avg    0.93369   0.93095   0.93091      1984\n",
      "\n",
      "\n",
      "Train loss: 0.13889 | Test f1: 0.9318, Test acc: 0.9309, Test PC 0.8974\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97884   0.90864   0.94244      1018\n",
      "           1    0.91049   0.97930   0.94364       966\n",
      "\n",
      "    accuracy                        0.94304      1984\n",
      "   macro avg    0.94466   0.94397   0.94304      1984\n",
      "weighted avg    0.94556   0.94304   0.94302      1984\n",
      "\n",
      "\n",
      "Train loss: 0.13889 | Test f1: 0.9436, Test acc: 0.9430, Test PC 0.9105\n",
      "\n",
      "Epoch: 3\n",
      "-------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97036   0.96464   0.96749      1018\n",
      "           1    0.96296   0.96894   0.96594       966\n",
      "\n",
      "    accuracy                        0.96673      1984\n",
      "   macro avg    0.96666   0.96679   0.96672      1984\n",
      "weighted avg    0.96676   0.96673   0.96674      1984\n",
      "\n",
      "\n",
      "Train loss: 0.13889 | Test f1: 0.9659, Test acc: 0.9667, Test PC 0.9630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Train_test_on_model(4,train_data_load2,test_data_load2,model) # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "190c3bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96000   0.94303   0.95144      1018\n",
      "           1    0.94106   0.95859   0.94974       966\n",
      "\n",
      "    accuracy                        0.95060      1984\n",
      "   macro avg    0.95053   0.95081   0.95059      1984\n",
      "weighted avg    0.95078   0.95060   0.95061      1984\n",
      "\n",
      "\n",
      "Train loss: 0.17544 | Test f1: 0.9497, Test acc: 0.9506, Test PC 0.9411\n",
      "\n",
      "Epoch: 1\n",
      "-------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97707   0.87917   0.92554      1018\n",
      "           1    0.88483   0.97826   0.92920       966\n",
      "\n",
      "    accuracy                        0.92742      1984\n",
      "   macro avg    0.93095   0.92872   0.92737      1984\n",
      "weighted avg    0.93216   0.92742   0.92733      1984\n",
      "\n",
      "\n",
      "Train loss: 0.17544 | Test f1: 0.9292, Test acc: 0.9274, Test PC 0.8848\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96657   0.93713   0.95162      1018\n",
      "           1    0.93581   0.96584   0.95059       966\n",
      "\n",
      "    accuracy                        0.95111      1984\n",
      "   macro avg    0.95119   0.95149   0.95110      1984\n",
      "weighted avg    0.95159   0.95111   0.95112      1984\n",
      "\n",
      "\n",
      "Train loss: 0.17544 | Test f1: 0.9506, Test acc: 0.9511, Test PC 0.9358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Train_test_on_model(3,train_data_load2,test_data_load2,model) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "496a819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'model6-5firsttwo_4all_'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7652722",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b95f301e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1200)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1200)\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab6721d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "116f8d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cam(img):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred_prob = model(img.to(device)).squeeze()\n",
    "        temp = torch.softmax(y_pred_prob,dim=0).argmax(dim=0)\n",
    "        y_pred = temp.to('cpu')\n",
    "#         torch.round(torch.sigmoid(y_pred_prob.to('cpu')))\n",
    "\n",
    "#         print(torch.softmax(y_pred_prob,dim=0).argmax(dim=0))\n",
    "        a = torch.softmax(y_pred_prob,dim=0)\n",
    "        a = torch.max(a, dim=0).values\n",
    "#         print(a)\n",
    "    return y_pred, a.to('cpu')\n",
    "# y_pred_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7e938b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(img):\n",
    "    transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "\n",
    "    ])\n",
    "    \n",
    "    img = transform(img)\n",
    "    img = img.to(dtype=torch.float)\n",
    "    img = img.unsqueeze(0)\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds = 0\n",
    "label =\" \"\n",
    "ret, image = cap.read()\n",
    "face_model = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "rect = cv2.rectangle(image,(1,1),(1,1), (0,255,0), 1)\n",
    "cv2.putText(image, 'mask',(1,1-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "y_pred,prob = None, None\n",
    "color = (0,0,0)\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "#     rect = cv2.rectangle(image,(1,1),(1,1), (0,255,0), 1)\n",
    "\n",
    "    cv2.imshow('img', image)\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    face = face_model.detectMultiScale(image_gray, 1.1, 4)\n",
    "#     print(image.shape)\n",
    "    if seconds == 1:\n",
    "        \n",
    "        for (x,y,w,h) in face:\n",
    "#         center = (x+w//2, y+h//2)\n",
    "            face1 = face\n",
    "            rect = cv2.rectangle(image,(x,y),(x+w+10,y+h+10), color, 1)\n",
    "\n",
    "            face1 = image[y: y+h+15, x: x+w+15]\n",
    "#             img = cv2.cvtColor(face1, cv2.COLOR_GRAY2RGB)\n",
    "    #         cv2.imshow('img', rect)\n",
    "            \n",
    "            img = pre_process(face1)\n",
    "    #         print(img.shape)\n",
    "            y_pred,prob = test_cam(img)\n",
    "    #         print(img.shape)\n",
    "#             y_pred,prob = test_cam(img)\n",
    "            cv2.putText(image, label,(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "            \n",
    "#         print(y_pred)\n",
    "#         if y_pred == 0:\n",
    "#             print(y_pred)\n",
    "        if y_pred == 1:\n",
    "            \n",
    "            label = 'Masked : '+ str((np.array(prob)*100))\n",
    "            color = (0,255,0)\n",
    "        elif y_pred == 3:\n",
    "            label = 'incorrect : '+str((np.array(prob)*100))\n",
    "            color = (255,0,0)\n",
    "        elif y_pred == 0:\n",
    "            label = 'No mask : '+str((np.array(prob)*100))\n",
    "            color = (0,0,255)\n",
    "        \n",
    "        \n",
    "        seconds = 0\n",
    "    else:\n",
    "        seconds +=1\n",
    "#     print(label)\n",
    "    \n",
    "    cv2.imshow('img', rect)\n",
    "    \n",
    "    \n",
    "#     image = cv2.rectangle(image,(100,150),(152,250), (250,0,0), 2)\n",
    "\n",
    "    \n",
    "    if cv2.waitKey(1):\n",
    "        pass\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c39ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
